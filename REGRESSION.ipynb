{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16aa9db4",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e421d514",
   "metadata": {},
   "source": [
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f06a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3285c18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X3</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>X12</th>\n",
       "      <th>X13</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>659</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13884.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1518</td>\n",
       "      <td>348.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>476</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6786.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1310</td>\n",
       "      <td>418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12948.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2029</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6884</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>4721</td>\n",
       "      <td>668.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14079.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3286</td>\n",
       "      <td>295.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11427.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3963</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13338.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>4200</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10296.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X1  X3  X5    X6      X8  X9  X10  X12  X13        Y\n",
       "0    0   0   0   659  1092.0   0    0    0    1  13884.0\n",
       "1    1   0   1  1518   348.0   0    0    1    1  11700.0\n",
       "2    2   0   0   476   504.0   0    0    1    1   6786.0\n",
       "3    3   0   0  1310   418.0   0    0    1    1  12948.0\n",
       "4    4   1   2  2029   108.0   0    0    0    0  11427.0\n",
       "..  ..  ..  ..   ...     ...  ..  ...  ...  ...      ...\n",
       "64  49   0   2  6884   337.0   0    0    0    0   9399.0\n",
       "65   8   0  13  4721   668.0   0    1    0    0  14079.0\n",
       "66  50   0   0  3286   295.0   0    0    0    0  11427.0\n",
       "67  51   1   7  3963     0.0   0    1    0    0  13338.0\n",
       "68   1   0  14  4200   101.0   0    0    0    0  10296.0\n",
       "\n",
       "[69 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Importing the dataset\n",
    "df = pd.read_csv('br_prep1.csv', sep=';')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a248e",
   "metadata": {},
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa9ff9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['Y']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde21f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1c856",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a568be68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.321"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Fitting Multiple Regression\n",
    "mr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Coefficient of determination R^2\n",
    "mr.score(X_train, y_train).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b6f8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising the Test set results\n",
    "plt.scatter(X_test['X3'], y_test, color = 'red')\n",
    "plt.plot(X_test['X3'], mr.predict(X_test), 'bo')\n",
    "plt.title('Y vs X3 (Test set)')\n",
    "plt.xlabel('X3')\n",
    "plt.ylabel('Y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6df481",
   "metadata": {},
   "source": [
    "# R2 = 0,321. Получено низкое качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceb68e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 27 Oct 2021</td> <th>  Prob (F-statistic):</th>  <td>0.0275</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:23:25</td>     <th>  Log-Likelihood:    </th> <td> -493.78</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    55</td>      <th>  AIC:               </th> <td>   1008.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1028.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     9</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  1.09e+04</td> <td>  904.321</td> <td>   12.051</td> <td> 0.000</td> <td> 9076.785</td> <td> 1.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>    <td>  -22.5054</td> <td>   21.307</td> <td>   -1.056</td> <td> 0.296</td> <td>  -65.420</td> <td>   20.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>    <td> 1339.9528</td> <td>  654.811</td> <td>    2.046</td> <td> 0.047</td> <td>   21.095</td> <td> 2658.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X5</th>    <td>  -19.9111</td> <td>   77.125</td> <td>   -0.258</td> <td> 0.797</td> <td> -175.248</td> <td>  135.426</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X6</th>    <td>   -0.0654</td> <td>    0.153</td> <td>   -0.427</td> <td> 0.672</td> <td>   -0.374</td> <td>    0.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X8</th>    <td>    1.4840</td> <td>    0.743</td> <td>    1.997</td> <td> 0.052</td> <td>   -0.013</td> <td>    2.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X9</th>    <td>   63.7717</td> <td> 1282.445</td> <td>    0.050</td> <td> 0.961</td> <td>-2519.205</td> <td> 2646.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X10</th>   <td>  897.8734</td> <td>  828.831</td> <td>    1.083</td> <td> 0.284</td> <td> -771.477</td> <td> 2567.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X12</th>   <td> 1519.7358</td> <td> 1200.135</td> <td>    1.266</td> <td> 0.212</td> <td> -897.460</td> <td> 3936.932</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X13</th>   <td> -794.7159</td> <td>  625.786</td> <td>   -1.270</td> <td> 0.211</td> <td>-2055.114</td> <td>  465.682</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>44.936</td> <th>  Durbin-Watson:     </th> <td>   2.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 212.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-2.110</td> <th>  Prob(JB):          </th> <td>8.15e-47</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td> <th>  Cond. No.          </th> <td>2.46e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.46e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.321\n",
       "Model:                            OLS   Adj. R-squared:                  0.186\n",
       "Method:                 Least Squares   F-statistic:                     2.369\n",
       "Date:                Wed, 27 Oct 2021   Prob (F-statistic):             0.0275\n",
       "Time:                        11:23:25   Log-Likelihood:                -493.78\n",
       "No. Observations:                  55   AIC:                             1008.\n",
       "Df Residuals:                      45   BIC:                             1028.\n",
       "Df Model:                           9                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        1.09e+04    904.321     12.051      0.000    9076.785    1.27e+04\n",
       "X1           -22.5054     21.307     -1.056      0.296     -65.420      20.409\n",
       "X3          1339.9528    654.811      2.046      0.047      21.095    2658.810\n",
       "X5           -19.9111     77.125     -0.258      0.797    -175.248     135.426\n",
       "X6            -0.0654      0.153     -0.427      0.672      -0.374       0.243\n",
       "X8             1.4840      0.743      1.997      0.052      -0.013       2.981\n",
       "X9            63.7717   1282.445      0.050      0.961   -2519.205    2646.749\n",
       "X10          897.8734    828.831      1.083      0.284    -771.477    2567.224\n",
       "X12         1519.7358   1200.135      1.266      0.212    -897.460    3936.932\n",
       "X13         -794.7159    625.786     -1.270      0.211   -2055.114     465.682\n",
       "==============================================================================\n",
       "Omnibus:                       44.936   Durbin-Watson:                   2.236\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              212.247\n",
       "Skew:                          -2.110   Prob(JB):                     8.15e-47\n",
       "Kurtosis:                      11.649   Cond. No.                     2.46e+04\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.46e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking p-values\n",
    "import statsmodels.api as sm\n",
    "X1 = sm.add_constant(X_train)\n",
    "mr1 = sm.OLS(y_train, X1).fit()\n",
    "#mr1.pvalues\n",
    "mr1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830db017",
   "metadata": {},
   "source": [
    "Количество значимых переменных - 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d47a2",
   "metadata": {},
   "source": [
    "# Recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50eb56f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature ranking with recursive feature elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "n_features = X.shape[1]\n",
    "estimator = LinearRegression()\n",
    "selector = RFE(estimator, n_features_to_select = 6)\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "# Selected Features\n",
    "selected_columns=[]\n",
    "for i in range(n_features):\n",
    "    if selector.support_[i] == True:\n",
    "        selected_columns.append(i)\n",
    "        \n",
    "f_lm = []\n",
    "for column in selected_columns:\n",
    "    f_lm.append(X.columns[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e25acedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -32.39194526, 1820.79155379,  423.69246665,  508.18842014,\n",
       "        1443.46698014, -715.61383325]),\n",
       " 11227.84640877538)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Optimized Multiple Regression\n",
    "mr_rfe = LinearRegression().fit(X_train[f_lm], y_train)\n",
    "\n",
    "# Getting parameters\n",
    "mr_rfe.coef_, mr_rfe.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5de4fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.258"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = mr_rfe.predict(X_test[f_lm])\n",
    "\n",
    "# Coefficient of determination R^2\n",
    "mr_rfe.score(X_train[f_lm], y_train).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62721319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2005.56, 2048.29)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean squared error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mean_squared_error(y_train, mr_rfe.predict(X_train[f_lm]), squared=False).round(2), mean_squared_error(y_test, y_pred, squared=False).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb757a17",
   "metadata": {},
   "source": [
    " Данные сопоставимы, значение R2 уменьшилось."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20e0ea",
   "metadata": {},
   "source": [
    "# Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19cd25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Backward Elimination with p-values\n",
    "def backwardElimination(x, y, sl):\n",
    "    x = sm.add_constant(x)\n",
    "    numVars = x.shape[1]\n",
    "    for i in range(0, numVars):\n",
    "        regressor_OLS = sm.OLS(y, x).fit()\n",
    "        maxVar = max(regressor_OLS.pvalues)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor_OLS.pvalues[j] == maxVar):\n",
    "                    x = x.drop(x.columns[j], axis=1)\n",
    "    regressor_OLS.summary()\n",
    "    return x\n",
    "\n",
    "SL = 0.1\n",
    "X_Modeled = backwardElimination(X_train, y_train, SL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04eea8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.213"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Optimized Multiple Regression\n",
    "mr_be = LinearRegression().fit(X_Modeled, y_train)\n",
    "\n",
    "# Coefficient of determination R^2\n",
    "mr_be.score(X_Modeled, y_train).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6818521",
   "metadata": {},
   "source": [
    "Минимальное значение для R2 по всем моделям. Качество остается низким."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbafe5e",
   "metadata": {},
   "source": [
    "# Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd874dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "obj = {'X_train': X_train, 'X_test': X_test,'y_train': y_train,'y_test': y_test}\n",
    "output = open('br_data_reg.pkl', 'wb')\n",
    "pickle.dump(obj, output, 2)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b8ad28",
   "metadata": {},
   "source": [
    "Таким образом, из всех моделей - лучшая модель множественной линейной регрессии."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
